{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zyp3iWVqc-cF"
   },
   "source": [
    "## Using TensorFlow to Generate Images with PixelRNNs\n",
    "Let's start by importing all the necessary dependencies.\n",
    "\n",
    "Note that, as mentioned in the article, this notebook will use a faster, simpler version of the PixelRNN architecture called PixelCNN, which just relies on a series of masked convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0W3w0m1oc-cI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import *\n",
    "from ops import *\n",
    "# from statistic import Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3BIzi9o0c-cP"
   },
   "source": [
    "### Set up the parameters\n",
    "Here we set all the paramaters for the PixelRNN model. These include the model hyperparameters, some dataset properties, and debugging information. We also set up the random seeds for Tensorflow and Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9Eey9Fqc-cQ"
   },
   "outputs": [],
   "source": [
    "hyperparams = {# network\n",
    "    \"model\" : \"pixel_cnn\", # name of model [pixel_rnn, pixel_cnn]\n",
    "    \"batch_size\" : 32, # size of a batch\n",
    "    \"hidden_dims\" : 16, # dimesion of hidden states of LSTM or Conv layers\n",
    "    \"recurrent_length\" : 8, # the length of LSTM or Conv layers\n",
    "    \"out_hidden_dims\" : 32, # dimesion of hidden states of output Conv layers\n",
    "    \"out_recurrent_length\" : 4, # the length of output Conv layers\n",
    "    \"use_residual\" : False, # whether to use residual connections or not\n",
    "    \"use_dynamic_rnn\" : False, # whether to use dynamic_rnn or not\n",
    "\n",
    "    # training\n",
    "    \"max_epoch\" : 200, # # of step in an epoch\n",
    "    \"test_step\" : 10, # # of step to test a model\n",
    "    \"save_step\" : 5, # # of step to save a model\n",
    "    \"learning_rate\" : 1e-3, # learning rate\n",
    "    \"grad_clip\" : 1, # value of gradient to be used for clipping\n",
    "    \"use_gpu\" : True, # whether to use gpu for training\n",
    "\n",
    "    #data\n",
    "    \"x_path\": \"music_x\",\n",
    "    \"y_path\": \"music_y\",\n",
    "    \"test_path\":\"test\",\n",
    "    \n",
    "    # Debug\n",
    "    \"is_train\" : True, # training or testing\n",
    "    \"display\" : False, # whether to display the training results or not\n",
    "    \"random_seed\" :  123 # random seed for python\n",
    "}\n",
    "p = dotdict(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SF-TLWjhc-cS"
   },
   "outputs": [],
   "source": [
    "if \"random_seed\" in p:\n",
    "    tf.set_random_seed(p.random_seed)\n",
    "    np.random.seed(p.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hj0224RQc-cU"
   },
   "source": [
    "### Prepare the dataset\n",
    "\n",
    "The music dataset for this project is 10 songs from one of Jay chou's albums. Use librosa to load the music data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29WiMxrhM6E4"
   },
   "outputs": [],
   "source": [
    "xfile = os.listdir(p.x_path)\n",
    "yfile = os.listdir(p.y_path)\n",
    "testfile = os.listdir(p.test_path)\n",
    "time_steps = 512\n",
    "height = 1\n",
    "width = time_steps\n",
    "X_train=np.zeros((1,time_steps))\n",
    "Y_train=np.zeros((1,time_steps))\n",
    "X_test=np.zeros((1,time_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "huI136LcRr7G"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "\n",
    "for file in xfile:\n",
    "  try:\n",
    "    y, sr = librosa.load(p.y_path+'/'+file, mono=True)\n",
    "    yc, sr = librosa.load(p.x_path+'/'+file, mono=True)\n",
    "    \n",
    "    music_length = len(y)\n",
    "    sequence_size = int(music_length/time_steps)\n",
    "    \n",
    "    x_train = np.zeros((sequence_size,time_steps))\n",
    "    y_train = np.zeros((sequence_size,time_steps))\n",
    "    \n",
    "    for i in range(sequence_size):\n",
    "      x_train[i] = yc[time_steps*i:time_steps*(i+1)]\n",
    "      y_train[i] = y[time_steps*i:time_steps*(i+1)]\n",
    "  \n",
    "    x_train = x_train.reshape(sequence_size,time_steps)[100:-100]\n",
    "    y_train = y_train.reshape(sequence_size,time_steps)[100:-100]\n",
    "    \n",
    "    X_train = np.concatenate((X_train,x_train))\n",
    "    Y_train = np.concatenate((Y_train,y_train))\n",
    "    \n",
    "  except IsADirectoryError:\n",
    "    pass\n",
    "  except FileNotFoundError:\n",
    "    pass\n",
    "  \n",
    "  \n",
    "for file in testfile:\n",
    "  try:\n",
    "    y, sr = librosa.load(p.test_path+'/'+file, mono=True)\n",
    "    music_length = len(y)\n",
    "    sequence_size = int(music_length/time_steps)\n",
    "    x_test = np.zeros((sequence_size,time_steps))\n",
    "    \n",
    "    for i in range(sequence_size):\n",
    "      x_test[i] = yc[time_steps*i:time_steps*(i+1)]\n",
    "      \n",
    "    x_test = x_test.reshape(sequence_size,time_steps)[100:-100]\n",
    "    X_test = np.concatenate((X_test,x_test))\n",
    "    \n",
    "  except IsADirectoryError:\n",
    "    pass\n",
    "  except FileNotFoundError:\n",
    "    pass\n",
    "    \n",
    "# l = int(len(X_train)*0.2)\n",
    "\n",
    "# X_test = X_train[:l]\n",
    "# Y_test = Y_train[:l]\n",
    "\n",
    "# X_train = X_train[l:]\n",
    "# Y_train = Y_train[l:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dx0vN9Zvc-cZ"
   },
   "source": [
    "### Setting up network\n",
    "\n",
    "Let's construct the PixelCNN model. First, we set up input placeholder. We'll be feeding batches of training images into the model through this.\n",
    "\n",
    "Next, we construct the masked convolutional layers. You can find the implementation of this masking procedure in ```ops.py```. These layers apply a series of convolutions to the image, where each filter is masked to only account for pixels in the region of interest. These are the pixels above and to the left of the pixel in the center of the mask, which follows the PixelRNN generative model assumptions. Also of note is that the receptive field of the PixelCNN model grows linearly with the depth of these convolutional stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1557258815632,
     "user": {
      "displayName": "Hao Wu",
      "photoUrl": "",
      "userId": "09053135221707931772"
     },
     "user_tz": 240
    },
    "id": "Vjr0o5UBc-cZ",
    "outputId": "8859811f-101b-48e5-a265-ad2c8517bf63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CONV0\n",
      "Building CONV1\n",
      "Building CONV2\n",
      "Building CONV3\n",
      "Building CONV4\n",
      "Building CONV5\n",
      "Building CONV6\n",
      "Building CONV7\n",
      "Building CONV_OUT0\n",
      "Building CONV_OUT1\n",
      "Building CONV_OUT2\n",
      "Building CONV_OUT3\n"
     ]
    }
   ],
   "source": [
    "def pixelRNN(height, width, channel, params):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    height, width, channel - the dimensions of the input\n",
    "    params -- the hyperparameters of the network\n",
    "    \"\"\"\n",
    "    input_shape = [None, height, width, channel] if params.use_gpu else [None, channel, height, width]\n",
    "    inputs = tf.placeholder(tf.float32, input_shape, name='inputs')\n",
    "    truth = tf.placeholder(tf.float32, input_shape, name='truth')\n",
    "    # input of main convolutional layers\n",
    "    scope = \"conv_inputs\"\n",
    "\n",
    "    conv_inputs = conv2d(inputs, params.hidden_dims, [1,63], \"A\", scope=scope)\n",
    "    # main convolutions layers    \n",
    "    last_hid = conv_inputs\n",
    "    for idx in range(params.recurrent_length):\n",
    "        scope = 'CONV%d' % idx\n",
    "        last_hid = conv2d(last_hid, 16, [1, 1], \"B\", scope=scope)\n",
    "        print(\"Building %s\" % scope)\n",
    "\n",
    "    # output convolutional layers\n",
    "    for idx in range(params.out_recurrent_length):\n",
    "        scope = 'CONV_OUT%d' % idx\n",
    "        last_hid = tf.nn.relu(conv2d(last_hid, params.out_hidden_dims, [1, 1], \"B\", scope=scope))\n",
    "        print(\"Building %s\" % scope)\n",
    "\n",
    "    conv2d_out_logits = conv2d(last_hid, 1, [1, 1], \"B\", scope='conv2d_out_logits')\n",
    "#     output = tf.nn.tanh(conv2d_out_logits)\n",
    "    output = conv2d_out_logits\n",
    "#     output = tf.layers.dense(conv2d_out_logits,units=1)\n",
    "    return inputs, truth, output, conv2d_out_logits\n",
    "\n",
    "tf.reset_default_graph()\n",
    "inputs, truth, output, conv2d_out_logits = pixelRNN(height, width, channel, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ggpyh8Nec-cc"
   },
   "source": [
    "### Optimization\n",
    "\n",
    "Now, let's train the model. To do so, we will minimize the cross entropy loss using an RMSPropOptimizer. We also clip the gradients to help deal with potential exploding gradient problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1214,
     "status": "ok",
     "timestamp": 1557258820100,
     "user": {
      "displayName": "Hao Wu",
      "photoUrl": "",
      "userId": "09053135221707931772"
     },
     "user_tz": 240
    },
    "id": "9VPi07mKc-cd",
    "outputId": "725b4e89-e9fe-4393-98bb-426a6049329a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pixel_cnn finished!\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.losses.mean_squared_error(truth,output))\n",
    "\n",
    "\n",
    "# loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=conv2d_out_logits, labels=truth, name='loss'))\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(p.learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "\n",
    "new_grads_and_vars = \\\n",
    "    [(tf.clip_by_value(gv[0], -p.grad_clip, p.grad_clip), gv[1]) for gv in grads_and_vars]\n",
    "optim = optimizer.apply_gradients(new_grads_and_vars)\n",
    "# optim = optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "# show_all_variables()\n",
    "print(\"Building %s finished!\" % p.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qz3rVN2pc-cf"
   },
   "source": [
    "### Image generation\n",
    "To generate an image, we predict a single pixel at a time. Once we generate a pixel, the next prediction will use the previous pixels to generate the next pixel intensity using the masked convolutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNufx5klc-cg"
   },
   "outputs": [],
   "source": [
    "def predict(sess, music, inputs, output):\n",
    "    return sess.run(output, {inputs: music})\n",
    "  \n",
    "\n",
    "def generate(sess, inputs, output, sample):\n",
    "    a = sess.run(output, {inputs:sample.reshape((4518,1,time_steps,1))})\n",
    "    result = a.flatten()\n",
    "    librosa.output.write_wav('result.wav',result,sr)\n",
    "    ipd.Audio('result.wav')\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89X0dO3Xc-ci"
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7271
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3437146,
     "status": "ok",
     "timestamp": 1557262263260,
     "user": {
      "displayName": "Hao Wu",
      "photoUrl": "",
      "userId": "09053135221707931772"
     },
     "user_tz": 240
    },
    "id": "YRatxoWTc-ci",
    "outputId": "45f4a314-05e4-4b18-8e87-4f6994058fdf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.053:   0%|          | 0/200 [00:17<?, ?it/s]\u001b[A\n",
      "train loss: 0.053:   0%|          | 1/200 [00:17<58:43, 17.70s/it]\u001b[A\n",
      "train loss: 0.054:   0%|          | 1/200 [00:34<58:43, 17.70s/it]\u001b[A\n",
      "train loss: 0.054:   1%|          | 2/200 [00:34<57:41, 17.48s/it]\u001b[A\n",
      "train loss: 0.053:   1%|          | 2/200 [00:51<57:41, 17.48s/it]\u001b[A\n",
      "train loss: 0.053:   2%|▏         | 3/200 [00:51<56:50, 17.31s/it]\u001b[A\n",
      "train loss: 0.055:   2%|▏         | 3/200 [01:08<56:50, 17.31s/it]\u001b[A\n",
      "train loss: 0.055:   2%|▏         | 4/200 [01:08<56:13, 17.21s/it]\u001b[A\n",
      "train loss: 0.049:   2%|▏         | 4/200 [01:25<56:13, 17.21s/it]\u001b[A\n",
      "train loss: 0.049:   2%|▎         | 5/200 [01:25<55:43, 17.15s/it]\u001b[A\n",
      "train loss: 0.058:   2%|▎         | 5/200 [01:42<55:43, 17.15s/it]\u001b[A\n",
      "train loss: 0.058:   3%|▎         | 6/200 [01:42<55:11, 17.07s/it]\u001b[A\n",
      "train loss: 0.053:   3%|▎         | 6/200 [01:59<55:11, 17.07s/it]\u001b[A\n",
      "train loss: 0.053:   4%|▎         | 7/200 [01:59<54:49, 17.04s/it]\u001b[A\n",
      "train loss: 0.055:   4%|▎         | 7/200 [02:16<54:49, 17.04s/it]\u001b[A\n",
      "train loss: 0.055:   4%|▍         | 8/200 [02:16<54:27, 17.02s/it]\u001b[A\n",
      "train loss: 0.053:   4%|▍         | 8/200 [02:33<54:27, 17.02s/it]\u001b[A\n",
      "train loss: 0.053:   4%|▍         | 9/200 [02:33<54:06, 17.00s/it]\u001b[A\n",
      "train loss: 0.054:   4%|▍         | 9/200 [02:50<54:06, 17.00s/it]\u001b[A\n",
      "train loss: 0.054:   5%|▌         | 10/200 [02:50<53:39, 16.95s/it]\u001b[A\n",
      "train loss: 0.054:   5%|▌         | 10/200 [03:07<53:39, 16.95s/it]\u001b[A\n",
      "train loss: 0.054:   6%|▌         | 11/200 [03:07<53:21, 16.94s/it]\u001b[A\n",
      "train loss: 0.052:   6%|▌         | 11/200 [03:23<53:21, 16.94s/it]\u001b[A\n",
      "train loss: 0.052:   6%|▌         | 12/200 [03:23<52:58, 16.91s/it]\u001b[A\n",
      "train loss: 0.055:   6%|▌         | 12/200 [03:40<52:58, 16.91s/it]\u001b[A\n",
      "train loss: 0.055:   6%|▋         | 13/200 [03:40<52:41, 16.91s/it]\u001b[A\n",
      "train loss: 0.051:   6%|▋         | 13/200 [03:57<52:41, 16.91s/it]\u001b[A\n",
      "train loss: 0.051:   7%|▋         | 14/200 [03:57<52:28, 16.93s/it]\u001b[A\n",
      "train loss: 0.056:   7%|▋         | 14/200 [04:14<52:28, 16.93s/it]\u001b[A\n",
      "train loss: 0.056:   8%|▊         | 15/200 [04:14<52:07, 16.91s/it]\u001b[A\n",
      "train loss: 0.054:   8%|▊         | 15/200 [04:31<52:07, 16.91s/it]\u001b[A\n",
      "train loss: 0.054:   8%|▊         | 16/200 [04:31<51:55, 16.93s/it]\u001b[A\n",
      "train loss: 0.053:   8%|▊         | 16/200 [04:48<51:55, 16.93s/it]\u001b[A\n",
      "train loss: 0.053:   8%|▊         | 17/200 [04:48<51:50, 17.00s/it]\u001b[A\n",
      "train loss: 0.054:   8%|▊         | 17/200 [05:05<51:50, 17.00s/it]\u001b[A\n",
      "train loss: 0.054:   9%|▉         | 18/200 [05:05<51:41, 17.04s/it]\u001b[A\n",
      "train loss: 0.054:   9%|▉         | 18/200 [05:23<51:41, 17.04s/it]\u001b[A\n",
      "train loss: 0.054:  10%|▉         | 19/200 [05:23<51:52, 17.20s/it]\u001b[A\n",
      "train loss: 0.054:  10%|▉         | 19/200 [05:40<51:52, 17.20s/it]\u001b[A\n",
      "train loss: 0.054:  10%|█         | 20/200 [05:40<51:21, 17.12s/it]\u001b[A\n",
      "train loss: 0.050:  10%|█         | 20/200 [05:57<51:21, 17.12s/it]\u001b[A\n",
      "train loss: 0.050:  10%|█         | 21/200 [05:57<50:52, 17.06s/it]\u001b[A\n",
      "train loss: 0.056:  10%|█         | 21/200 [06:14<50:52, 17.06s/it]\u001b[A\n",
      "train loss: 0.056:  11%|█         | 22/200 [06:14<50:34, 17.05s/it]\u001b[A\n",
      "train loss: 0.052:  11%|█         | 22/200 [06:31<50:34, 17.05s/it]\u001b[A\n",
      "train loss: 0.052:  12%|█▏        | 23/200 [06:31<50:21, 17.07s/it]\u001b[A\n",
      "train loss: 0.055:  12%|█▏        | 23/200 [06:48<50:21, 17.07s/it]\u001b[A\n",
      "train loss: 0.055:  12%|█▏        | 24/200 [06:48<49:58, 17.04s/it]\u001b[A\n",
      "train loss: 0.053:  12%|█▏        | 24/200 [07:05<49:58, 17.04s/it]\u001b[A\n",
      "train loss: 0.053:  12%|█▎        | 25/200 [07:05<49:36, 17.01s/it]\u001b[A\n",
      "train loss: 0.054:  12%|█▎        | 25/200 [07:22<49:36, 17.01s/it]\u001b[A\n",
      "train loss: 0.054:  13%|█▎        | 26/200 [07:22<49:16, 16.99s/it]\u001b[A\n",
      "train loss: 0.054:  13%|█▎        | 26/200 [07:39<49:16, 16.99s/it]\u001b[A\n",
      "train loss: 0.054:  14%|█▎        | 27/200 [07:39<48:54, 16.96s/it]\u001b[A\n",
      "train loss: 0.052:  14%|█▎        | 27/200 [07:56<48:54, 16.96s/it]\u001b[A\n",
      "train loss: 0.052:  14%|█▍        | 28/200 [07:56<48:37, 16.96s/it]\u001b[A\n",
      "train loss: 0.055:  14%|█▍        | 28/200 [08:13<48:37, 16.96s/it]\u001b[A\n",
      "train loss: 0.055:  14%|█▍        | 29/200 [08:13<48:17, 16.94s/it]\u001b[A\n",
      "train loss: 0.051:  14%|█▍        | 29/200 [08:30<48:17, 16.94s/it]\u001b[A\n",
      "train loss: 0.051:  15%|█▌        | 30/200 [08:30<47:59, 16.94s/it]\u001b[A\n",
      "train loss: 0.057:  15%|█▌        | 30/200 [08:47<47:59, 16.94s/it]\u001b[A\n",
      "train loss: 0.057:  16%|█▌        | 31/200 [08:47<47:45, 16.96s/it]\u001b[A\n",
      "train loss: 0.054:  16%|█▌        | 31/200 [09:03<47:45, 16.96s/it]\u001b[A\n",
      "train loss: 0.054:  16%|█▌        | 32/200 [09:03<47:24, 16.93s/it]\u001b[A\n",
      "train loss: 0.053:  16%|█▌        | 32/200 [09:20<47:24, 16.93s/it]\u001b[A\n",
      "train loss: 0.053:  16%|█▋        | 33/200 [09:20<47:08, 16.94s/it]\u001b[A\n",
      "train loss: 0.054:  16%|█▋        | 33/200 [09:37<47:08, 16.94s/it]\u001b[A\n",
      "train loss: 0.054:  17%|█▋        | 34/200 [09:37<46:51, 16.94s/it]\u001b[A\n",
      "train loss: 0.054:  17%|█▋        | 34/200 [09:54<46:51, 16.94s/it]\u001b[A\n",
      "train loss: 0.054:  18%|█▊        | 35/200 [09:54<46:36, 16.95s/it]\u001b[A\n",
      "train loss: 0.054:  18%|█▊        | 35/200 [10:11<46:36, 16.95s/it]\u001b[A\n",
      "train loss: 0.054:  18%|█▊        | 36/200 [10:11<46:31, 17.02s/it]\u001b[A\n",
      "train loss: 0.051:  18%|█▊        | 36/200 [10:29<46:31, 17.02s/it]\u001b[A\n",
      "train loss: 0.051:  18%|█▊        | 37/200 [10:29<46:24, 17.08s/it]\u001b[A\n",
      "train loss: 0.055:  18%|█▊        | 37/200 [10:46<46:24, 17.08s/it]\u001b[A\n",
      "train loss: 0.055:  19%|█▉        | 38/200 [10:46<46:17, 17.14s/it]\u001b[A\n",
      "train loss: 0.052:  19%|█▉        | 38/200 [11:03<46:17, 17.14s/it]\u001b[A\n",
      "train loss: 0.052:  20%|█▉        | 39/200 [11:03<45:47, 17.07s/it]\u001b[A\n",
      "train loss: 0.056:  20%|█▉        | 39/200 [11:20<45:47, 17.07s/it]\u001b[A\n",
      "train loss: 0.056:  20%|██        | 40/200 [11:20<45:30, 17.06s/it]\u001b[A\n",
      "train loss: 0.053:  20%|██        | 40/200 [11:37<45:30, 17.06s/it]\u001b[A\n",
      "train loss: 0.053:  20%|██        | 41/200 [11:37<45:08, 17.04s/it]\u001b[A\n",
      "train loss: 0.054:  20%|██        | 41/200 [11:54<45:08, 17.04s/it]\u001b[A\n",
      "train loss: 0.054:  21%|██        | 42/200 [11:54<44:47, 17.01s/it]\u001b[A\n",
      "train loss: 0.054:  21%|██        | 42/200 [12:11<44:47, 17.01s/it]\u001b[A\n",
      "train loss: 0.054:  22%|██▏       | 43/200 [12:11<44:26, 16.99s/it]\u001b[A\n",
      "train loss: 0.052:  22%|██▏       | 43/200 [12:28<44:26, 16.99s/it]\u001b[A\n",
      "train loss: 0.052:  22%|██▏       | 44/200 [12:28<44:12, 17.01s/it]\u001b[A\n",
      "train loss: 0.055:  22%|██▏       | 44/200 [12:45<44:12, 17.01s/it]\u001b[A\n",
      "train loss: 0.055:  22%|██▎       | 45/200 [12:45<43:59, 17.03s/it]\u001b[A\n",
      "train loss: 0.050:  22%|██▎       | 45/200 [13:02<43:59, 17.03s/it]\u001b[A\n",
      "train loss: 0.050:  23%|██▎       | 46/200 [13:02<43:42, 17.03s/it]\u001b[A\n",
      "train loss: 0.057:  23%|██▎       | 46/200 [13:19<43:42, 17.03s/it]\u001b[A\n",
      "train loss: 0.057:  24%|██▎       | 47/200 [13:19<43:24, 17.03s/it]\u001b[A\n",
      "train loss: 0.054:  24%|██▎       | 47/200 [13:36<43:24, 17.03s/it]\u001b[A\n",
      "train loss: 0.054:  24%|██▍       | 48/200 [13:36<43:05, 17.01s/it]\u001b[A\n",
      "train loss: 0.053:  24%|██▍       | 48/200 [13:53<43:05, 17.01s/it]\u001b[A\n",
      "train loss: 0.053:  24%|██▍       | 49/200 [13:53<42:53, 17.04s/it]\u001b[A\n",
      "train loss: 0.054:  24%|██▍       | 49/200 [14:10<42:53, 17.04s/it]\u001b[A\n",
      "train loss: 0.054:  25%|██▌       | 50/200 [14:10<42:37, 17.05s/it]\u001b[A\n",
      "train loss: 0.054:  25%|██▌       | 50/200 [14:27<42:37, 17.05s/it]\u001b[A\n",
      "train loss: 0.054:  26%|██▌       | 51/200 [14:27<42:25, 17.09s/it]\u001b[A\n",
      "train loss: 0.054:  26%|██▌       | 51/200 [14:44<42:25, 17.09s/it]\u001b[A\n",
      "train loss: 0.054:  26%|██▌       | 52/200 [14:44<42:04, 17.06s/it]\u001b[A\n",
      "train loss: 0.052:  26%|██▌       | 52/200 [15:01<42:04, 17.06s/it]\u001b[A\n",
      "train loss: 0.052:  26%|██▋       | 53/200 [15:01<41:48, 17.07s/it]\u001b[A\n",
      "train loss: 0.054:  26%|██▋       | 53/200 [15:19<41:48, 17.07s/it]\u001b[A\n",
      "train loss: 0.054:  27%|██▋       | 54/200 [15:19<41:36, 17.10s/it]\u001b[A\n",
      "train loss: 0.052:  27%|██▋       | 54/200 [15:35<41:36, 17.10s/it]\u001b[A\n",
      "train loss: 0.052:  28%|██▊       | 55/200 [15:35<41:11, 17.05s/it]\u001b[A\n",
      "train loss: 0.056:  28%|██▊       | 55/200 [15:53<41:11, 17.05s/it]\u001b[A\n",
      "train loss: 0.056:  28%|██▊       | 56/200 [15:53<41:19, 17.22s/it]\u001b[A\n",
      "train loss: 0.053:  28%|██▊       | 56/200 [16:10<41:19, 17.22s/it]\u001b[A\n",
      "train loss: 0.053:  28%|██▊       | 57/200 [16:10<40:49, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  28%|██▊       | 57/200 [16:27<40:49, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  29%|██▉       | 58/200 [16:27<40:36, 17.16s/it]\u001b[A\n",
      "train loss: 0.054:  29%|██▉       | 58/200 [16:44<40:36, 17.16s/it]\u001b[A\n",
      "train loss: 0.054:  30%|██▉       | 59/200 [16:44<40:11, 17.11s/it]\u001b[A\n",
      "train loss: 0.052:  30%|██▉       | 59/200 [17:01<40:11, 17.11s/it]\u001b[A\n",
      "train loss: 0.052:  30%|███       | 60/200 [17:01<39:47, 17.05s/it]\u001b[A\n",
      "train loss: 0.055:  30%|███       | 60/200 [17:18<39:47, 17.05s/it]\u001b[A\n",
      "train loss: 0.055:  30%|███       | 61/200 [17:18<39:26, 17.03s/it]\u001b[A\n",
      "train loss: 0.050:  30%|███       | 61/200 [17:35<39:26, 17.03s/it]\u001b[A\n",
      "train loss: 0.050:  31%|███       | 62/200 [17:35<39:03, 16.98s/it]\u001b[A\n",
      "train loss: 0.057:  31%|███       | 62/200 [17:52<39:03, 16.98s/it]\u001b[A\n",
      "train loss: 0.057:  32%|███▏      | 63/200 [17:52<38:50, 17.01s/it]\u001b[A\n",
      "train loss: 0.053:  32%|███▏      | 63/200 [18:09<38:50, 17.01s/it]\u001b[A\n",
      "train loss: 0.053:  32%|███▏      | 64/200 [18:09<38:41, 17.07s/it]\u001b[A\n",
      "train loss: 0.054:  32%|███▏      | 64/200 [18:27<38:41, 17.07s/it]\u001b[A\n",
      "train loss: 0.054:  32%|███▎      | 65/200 [18:27<38:32, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  32%|███▎      | 65/200 [18:44<38:32, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  33%|███▎      | 66/200 [18:44<38:15, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  33%|███▎      | 66/200 [19:01<38:15, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  34%|███▎      | 67/200 [19:01<37:58, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  34%|███▎      | 67/200 [19:18<37:58, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  34%|███▍      | 68/200 [19:18<37:34, 17.08s/it]\u001b[A\n",
      "train loss: 0.052:  34%|███▍      | 68/200 [19:35<37:34, 17.08s/it]\u001b[A\n",
      "train loss: 0.052:  34%|███▍      | 69/200 [19:35<37:10, 17.02s/it]\u001b[A\n",
      "train loss: 0.054:  34%|███▍      | 69/200 [19:52<37:10, 17.02s/it]\u001b[A\n",
      "train loss: 0.054:  35%|███▌      | 70/200 [19:52<36:53, 17.02s/it]\u001b[A\n",
      "train loss: 0.052:  35%|███▌      | 70/200 [20:09<36:53, 17.02s/it]\u001b[A\n",
      "train loss: 0.052:  36%|███▌      | 71/200 [20:09<36:37, 17.03s/it]\u001b[A\n",
      "train loss: 0.056:  36%|███▌      | 71/200 [20:26<36:37, 17.03s/it]\u001b[A\n",
      "train loss: 0.056:  36%|███▌      | 72/200 [20:26<36:28, 17.10s/it]\u001b[A\n",
      "train loss: 0.054:  36%|███▌      | 72/200 [20:43<36:28, 17.10s/it]\u001b[A\n",
      "train loss: 0.054:  36%|███▋      | 73/200 [20:43<36:05, 17.05s/it]\u001b[A\n",
      "train loss: 0.053:  36%|███▋      | 73/200 [21:00<36:05, 17.05s/it]\u001b[A\n",
      "train loss: 0.053:  37%|███▋      | 74/200 [21:00<36:03, 17.17s/it]\u001b[A\n",
      "train loss: 0.054:  37%|███▋      | 74/200 [21:17<36:03, 17.17s/it]\u001b[A\n",
      "train loss: 0.054:  38%|███▊      | 75/200 [21:17<35:41, 17.13s/it]\u001b[A\n",
      "train loss: 0.052:  38%|███▊      | 75/200 [21:34<35:41, 17.13s/it]\u001b[A\n",
      "train loss: 0.052:  38%|███▊      | 76/200 [21:34<35:21, 17.11s/it]\u001b[A\n",
      "train loss: 0.055:  38%|███▊      | 76/200 [21:52<35:21, 17.11s/it]\u001b[A\n",
      "train loss: 0.055:  38%|███▊      | 77/200 [21:52<35:02, 17.09s/it]\u001b[A\n",
      "train loss: 0.049:  38%|███▊      | 77/200 [22:08<35:02, 17.09s/it]\u001b[A\n",
      "train loss: 0.049:  39%|███▉      | 78/200 [22:08<34:41, 17.06s/it]\u001b[A\n",
      "train loss: 0.057:  39%|███▉      | 78/200 [22:26<34:41, 17.06s/it]\u001b[A\n",
      "train loss: 0.057:  40%|███▉      | 79/200 [22:26<34:23, 17.05s/it]\u001b[A\n",
      "train loss: 0.053:  40%|███▉      | 79/200 [22:43<34:23, 17.05s/it]\u001b[A\n",
      "train loss: 0.053:  40%|████      | 80/200 [22:43<34:05, 17.05s/it]\u001b[A\n",
      "train loss: 0.055:  40%|████      | 80/200 [23:00<34:05, 17.05s/it]\u001b[A\n",
      "train loss: 0.055:  40%|████      | 81/200 [23:00<33:52, 17.08s/it]\u001b[A\n",
      "train loss: 0.053:  40%|████      | 81/200 [23:17<33:52, 17.08s/it]\u001b[A\n",
      "train loss: 0.053:  41%|████      | 82/200 [23:17<33:33, 17.06s/it]\u001b[A\n",
      "train loss: 0.054:  41%|████      | 82/200 [23:34<33:33, 17.06s/it]\u001b[A\n",
      "train loss: 0.054:  42%|████▏     | 83/200 [23:34<33:15, 17.06s/it]\u001b[A\n",
      "train loss: 0.054:  42%|████▏     | 83/200 [23:51<33:15, 17.06s/it]\u001b[A\n",
      "train loss: 0.054:  42%|████▏     | 84/200 [23:51<32:58, 17.05s/it]\u001b[A\n",
      "train loss: 0.052:  42%|████▏     | 84/200 [24:08<32:58, 17.05s/it]\u001b[A\n",
      "train loss: 0.052:  42%|████▎     | 85/200 [24:08<32:43, 17.08s/it]\u001b[A\n",
      "train loss: 0.055:  42%|████▎     | 85/200 [24:25<32:43, 17.08s/it]\u001b[A\n",
      "train loss: 0.055:  43%|████▎     | 86/200 [24:25<32:28, 17.09s/it]\u001b[A\n",
      "train loss: 0.051:  43%|████▎     | 86/200 [24:42<32:28, 17.09s/it]\u001b[A\n",
      "train loss: 0.051:  44%|████▎     | 87/200 [24:42<32:10, 17.09s/it]\u001b[A\n",
      "train loss: 0.056:  44%|████▎     | 87/200 [24:59<32:10, 17.09s/it]\u001b[A\n",
      "train loss: 0.056:  44%|████▍     | 88/200 [24:59<31:59, 17.14s/it]\u001b[A\n",
      "train loss: 0.054:  44%|████▍     | 88/200 [25:17<31:59, 17.14s/it]\u001b[A\n",
      "train loss: 0.054:  44%|████▍     | 89/200 [25:17<31:47, 17.18s/it]\u001b[A\n",
      "train loss: 0.053:  44%|████▍     | 89/200 [25:34<31:47, 17.18s/it]\u001b[A\n",
      "train loss: 0.053:  45%|████▌     | 90/200 [25:34<31:36, 17.24s/it]\u001b[A\n",
      "train loss: 0.054:  45%|████▌     | 90/200 [25:51<31:36, 17.24s/it]\u001b[A\n",
      "train loss: 0.054:  46%|████▌     | 91/200 [25:51<31:19, 17.24s/it]\u001b[A\n",
      "train loss: 0.053:  46%|████▌     | 91/200 [26:09<31:19, 17.24s/it]\u001b[A\n",
      "train loss: 0.053:  46%|████▌     | 92/200 [26:09<31:21, 17.42s/it]\u001b[A\n",
      "train loss: 0.055:  46%|████▌     | 92/200 [26:27<31:21, 17.42s/it]\u001b[A\n",
      "train loss: 0.055:  46%|████▋     | 93/200 [26:27<31:02, 17.40s/it]\u001b[A\n",
      "train loss: 0.049:  46%|████▋     | 93/200 [26:44<31:02, 17.40s/it]\u001b[A\n",
      "train loss: 0.049:  47%|████▋     | 94/200 [26:44<30:38, 17.35s/it]\u001b[A\n",
      "train loss: 0.058:  47%|████▋     | 94/200 [27:01<30:38, 17.35s/it]\u001b[A\n",
      "train loss: 0.058:  48%|████▊     | 95/200 [27:01<30:13, 17.27s/it]\u001b[A\n",
      "train loss: 0.053:  48%|████▊     | 95/200 [27:18<30:13, 17.27s/it]\u001b[A\n",
      "train loss: 0.053:  48%|████▊     | 96/200 [27:18<29:57, 17.28s/it]\u001b[A\n",
      "train loss: 0.055:  48%|████▊     | 96/200 [27:35<29:57, 17.28s/it]\u001b[A\n",
      "train loss: 0.055:  48%|████▊     | 97/200 [27:35<29:36, 17.24s/it]\u001b[A\n",
      "train loss: 0.053:  48%|████▊     | 97/200 [27:52<29:36, 17.24s/it]\u001b[A\n",
      "train loss: 0.053:  49%|████▉     | 98/200 [27:52<29:15, 17.21s/it]\u001b[A\n",
      "train loss: 0.054:  49%|████▉     | 98/200 [28:10<29:15, 17.21s/it]\u001b[A\n",
      "train loss: 0.054:  50%|████▉     | 99/200 [28:10<28:59, 17.22s/it]\u001b[A\n",
      "train loss: 0.054:  50%|████▉     | 99/200 [28:27<28:59, 17.22s/it]\u001b[A\n",
      "train loss: 0.054:  50%|█████     | 100/200 [28:27<28:43, 17.23s/it]\u001b[A\n",
      "train loss: 0.052:  50%|█████     | 100/200 [28:44<28:43, 17.23s/it]\u001b[A\n",
      "train loss: 0.052:  50%|█████     | 101/200 [28:44<28:26, 17.23s/it]\u001b[A\n",
      "train loss: 0.055:  50%|█████     | 101/200 [29:01<28:26, 17.23s/it]\u001b[A\n",
      "train loss: 0.055:  51%|█████     | 102/200 [29:01<28:09, 17.24s/it]\u001b[A\n",
      "train loss: 0.051:  51%|█████     | 102/200 [29:19<28:09, 17.24s/it]\u001b[A\n",
      "train loss: 0.051:  52%|█████▏    | 103/200 [29:19<27:50, 17.22s/it]\u001b[A\n",
      "train loss: 0.056:  52%|█████▏    | 103/200 [29:36<27:50, 17.22s/it]\u001b[A\n",
      "train loss: 0.056:  52%|█████▏    | 104/200 [29:36<27:31, 17.20s/it]\u001b[A\n",
      "train loss: 0.054:  52%|█████▏    | 104/200 [29:53<27:31, 17.20s/it]\u001b[A\n",
      "train loss: 0.054:  52%|█████▎    | 105/200 [29:53<27:14, 17.20s/it]\u001b[A\n",
      "train loss: 0.053:  52%|█████▎    | 105/200 [30:10<27:14, 17.20s/it]\u001b[A\n",
      "train loss: 0.053:  53%|█████▎    | 106/200 [30:10<26:54, 17.17s/it]\u001b[A\n",
      "train loss: 0.054:  53%|█████▎    | 106/200 [30:28<26:54, 17.17s/it]\u001b[A\n",
      "train loss: 0.054:  54%|█████▎    | 107/200 [30:28<26:51, 17.33s/it]\u001b[A\n",
      "train loss: 0.054:  54%|█████▎    | 107/200 [30:45<26:51, 17.33s/it]\u001b[A\n",
      "train loss: 0.054:  54%|█████▍    | 108/200 [30:45<26:35, 17.34s/it]\u001b[A\n",
      "train loss: 0.054:  54%|█████▍    | 108/200 [31:03<26:35, 17.34s/it]\u001b[A\n",
      "train loss: 0.054:  55%|█████▍    | 109/200 [31:03<26:19, 17.36s/it]\u001b[A\n",
      "train loss: 0.050:  55%|█████▍    | 109/200 [31:21<26:19, 17.36s/it]\u001b[A\n",
      "train loss: 0.050:  55%|█████▌    | 110/200 [31:21<26:28, 17.65s/it]\u001b[A\n",
      "train loss: 0.056:  55%|█████▌    | 110/200 [31:38<26:28, 17.65s/it]\u001b[A\n",
      "train loss: 0.056:  56%|█████▌    | 111/200 [31:38<26:05, 17.59s/it]\u001b[A\n",
      "train loss: 0.053:  56%|█████▌    | 111/200 [31:56<26:05, 17.59s/it]\u001b[A\n",
      "train loss: 0.053:  56%|█████▌    | 112/200 [31:56<25:42, 17.53s/it]\u001b[A\n",
      "train loss: 0.055:  56%|█████▌    | 112/200 [32:13<25:42, 17.53s/it]\u001b[A\n",
      "train loss: 0.055:  56%|█████▋    | 113/200 [32:13<25:18, 17.45s/it]\u001b[A\n",
      "train loss: 0.053:  56%|█████▋    | 113/200 [32:30<25:18, 17.45s/it]\u001b[A\n",
      "train loss: 0.053:  57%|█████▋    | 114/200 [32:30<24:59, 17.44s/it]\u001b[A\n",
      "train loss: 0.054:  57%|█████▋    | 114/200 [32:48<24:59, 17.44s/it]\u001b[A\n",
      "train loss: 0.054:  57%|█████▊    | 115/200 [32:48<24:36, 17.37s/it]\u001b[A\n",
      "train loss: 0.054:  57%|█████▊    | 115/200 [33:05<24:36, 17.37s/it]\u001b[A\n",
      "train loss: 0.054:  58%|█████▊    | 116/200 [33:05<24:18, 17.36s/it]\u001b[A\n",
      "train loss: 0.052:  58%|█████▊    | 116/200 [33:22<24:18, 17.36s/it]\u001b[A\n",
      "train loss: 0.052:  58%|█████▊    | 117/200 [33:22<24:00, 17.35s/it]\u001b[A\n",
      "train loss: 0.055:  58%|█████▊    | 117/200 [33:39<24:00, 17.35s/it]\u001b[A\n",
      "train loss: 0.055:  59%|█████▉    | 118/200 [33:39<23:38, 17.30s/it]\u001b[A\n",
      "train loss: 0.051:  59%|█████▉    | 118/200 [33:57<23:38, 17.30s/it]\u001b[A\n",
      "train loss: 0.051:  60%|█████▉    | 119/200 [33:57<23:22, 17.31s/it]\u001b[A\n",
      "train loss: 0.057:  60%|█████▉    | 119/200 [34:14<23:22, 17.31s/it]\u001b[A\n",
      "train loss: 0.057:  60%|██████    | 120/200 [34:14<23:08, 17.35s/it]\u001b[A\n",
      "train loss: 0.054:  60%|██████    | 120/200 [34:32<23:08, 17.35s/it]\u001b[A\n",
      "train loss: 0.054:  60%|██████    | 121/200 [34:32<22:51, 17.36s/it]\u001b[A\n",
      "train loss: 0.053:  60%|██████    | 121/200 [34:49<22:51, 17.36s/it]\u001b[A\n",
      "train loss: 0.053:  61%|██████    | 122/200 [34:49<22:32, 17.34s/it]\u001b[A\n",
      "train loss: 0.055:  61%|██████    | 122/200 [35:06<22:32, 17.34s/it]\u001b[A\n",
      "train loss: 0.055:  62%|██████▏   | 123/200 [35:06<22:13, 17.32s/it]\u001b[A\n",
      "train loss: 0.054:  62%|██████▏   | 123/200 [35:23<22:13, 17.32s/it]\u001b[A\n",
      "train loss: 0.054:  62%|██████▏   | 124/200 [35:23<21:55, 17.31s/it]\u001b[A\n",
      "train loss: 0.053:  62%|██████▏   | 124/200 [35:41<21:55, 17.31s/it]\u001b[A\n",
      "train loss: 0.053:  62%|██████▎   | 125/200 [35:41<21:41, 17.35s/it]\u001b[A\n",
      "train loss: 0.051:  62%|██████▎   | 125/200 [35:58<21:41, 17.35s/it]\u001b[A\n",
      "train loss: 0.051:  63%|██████▎   | 126/200 [35:58<21:21, 17.32s/it]\u001b[A\n",
      "train loss: 0.055:  63%|██████▎   | 126/200 [36:15<21:21, 17.32s/it]\u001b[A\n",
      "train loss: 0.055:  64%|██████▎   | 127/200 [36:15<21:03, 17.31s/it]\u001b[A\n",
      "train loss: 0.052:  64%|██████▎   | 127/200 [36:33<21:03, 17.31s/it]\u001b[A\n",
      "train loss: 0.052:  64%|██████▍   | 128/200 [36:33<20:59, 17.50s/it]\u001b[A\n",
      "train loss: 0.055:  64%|██████▍   | 128/200 [36:51<20:59, 17.50s/it]\u001b[A\n",
      "train loss: 0.055:  64%|██████▍   | 129/200 [36:51<20:38, 17.44s/it]\u001b[A\n",
      "train loss: 0.053:  64%|██████▍   | 129/200 [37:08<20:38, 17.44s/it]\u001b[A\n",
      "train loss: 0.053:  65%|██████▌   | 130/200 [37:08<20:11, 17.30s/it]\u001b[A\n",
      "train loss: 0.054:  65%|██████▌   | 130/200 [37:25<20:11, 17.30s/it]\u001b[A\n",
      "train loss: 0.054:  66%|██████▌   | 131/200 [37:25<19:51, 17.27s/it]\u001b[A\n",
      "train loss: 0.054:  66%|██████▌   | 131/200 [37:42<19:51, 17.27s/it]\u001b[A\n",
      "train loss: 0.054:  66%|██████▌   | 132/200 [37:42<19:32, 17.24s/it]\u001b[A\n",
      "train loss: 0.052:  66%|██████▌   | 132/200 [37:59<19:32, 17.24s/it]\u001b[A\n",
      "train loss: 0.052:  66%|██████▋   | 133/200 [37:59<19:15, 17.24s/it]\u001b[A\n",
      "train loss: 0.055:  66%|██████▋   | 133/200 [38:17<19:15, 17.24s/it]\u001b[A\n",
      "train loss: 0.055:  67%|██████▋   | 134/200 [38:17<18:59, 17.27s/it]\u001b[A\n",
      "train loss: 0.050:  67%|██████▋   | 134/200 [38:34<18:59, 17.27s/it]\u001b[A\n",
      "train loss: 0.050:  68%|██████▊   | 135/200 [38:34<18:40, 17.24s/it]\u001b[A\n",
      "train loss: 0.057:  68%|██████▊   | 135/200 [38:51<18:40, 17.24s/it]\u001b[A\n",
      "train loss: 0.057:  68%|██████▊   | 136/200 [38:51<18:19, 17.19s/it]\u001b[A\n",
      "train loss: 0.054:  68%|██████▊   | 136/200 [39:08<18:19, 17.19s/it]\u001b[A\n",
      "train loss: 0.054:  68%|██████▊   | 137/200 [39:08<17:59, 17.14s/it]\u001b[A\n",
      "train loss: 0.053:  68%|██████▊   | 137/200 [39:25<17:59, 17.14s/it]\u001b[A\n",
      "train loss: 0.053:  69%|██████▉   | 138/200 [39:25<17:42, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  69%|██████▉   | 138/200 [39:42<17:42, 17.13s/it]\u001b[A\n",
      "train loss: 0.054:  70%|██████▉   | 139/200 [39:42<17:26, 17.16s/it]\u001b[A\n",
      "train loss: 0.055:  70%|██████▉   | 139/200 [40:00<17:26, 17.16s/it]\u001b[A\n",
      "train loss: 0.055:  70%|███████   | 140/200 [40:00<17:12, 17.21s/it]\u001b[A\n",
      "train loss: 0.054:  70%|███████   | 140/200 [40:17<17:12, 17.21s/it]\u001b[A\n",
      "train loss: 0.054:  70%|███████   | 141/200 [40:17<16:54, 17.20s/it]\u001b[A\n",
      "train loss: 0.052:  70%|███████   | 141/200 [40:34<16:54, 17.20s/it]\u001b[A\n",
      "train loss: 0.052:  71%|███████   | 142/200 [40:34<16:37, 17.20s/it]\u001b[A\n",
      "train loss: 0.055:  71%|███████   | 142/200 [40:51<16:37, 17.20s/it]\u001b[A\n",
      "train loss: 0.055:  72%|███████▏  | 143/200 [40:51<16:25, 17.29s/it]\u001b[A\n",
      "train loss: 0.052:  72%|███████▏  | 143/200 [41:09<16:25, 17.29s/it]\u001b[A\n",
      "train loss: 0.052:  72%|███████▏  | 144/200 [41:09<16:11, 17.35s/it]\u001b[A\n",
      "train loss: 0.056:  72%|███████▏  | 144/200 [41:27<16:11, 17.35s/it]\u001b[A\n",
      "train loss: 0.056:  72%|███████▎  | 145/200 [41:27<15:58, 17.42s/it]\u001b[A\n",
      "train loss: 0.053:  72%|███████▎  | 145/200 [41:45<15:58, 17.42s/it]\u001b[A\n",
      "train loss: 0.053:  73%|███████▎  | 146/200 [41:45<15:53, 17.66s/it]\u001b[A\n",
      "train loss: 0.054:  73%|███████▎  | 146/200 [42:02<15:53, 17.66s/it]\u001b[A\n",
      "train loss: 0.054:  74%|███████▎  | 147/200 [42:02<15:32, 17.59s/it]\u001b[A\n",
      "train loss: 0.054:  74%|███████▎  | 147/200 [42:20<15:32, 17.59s/it]\u001b[A\n",
      "train loss: 0.054:  74%|███████▍  | 148/200 [42:20<15:11, 17.54s/it]\u001b[A\n",
      "train loss: 0.052:  74%|███████▍  | 148/200 [42:37<15:11, 17.54s/it]\u001b[A\n",
      "train loss: 0.052:  74%|███████▍  | 149/200 [42:37<14:52, 17.50s/it]\u001b[A\n",
      "train loss: 0.056:  74%|███████▍  | 149/200 [42:54<14:52, 17.50s/it]\u001b[A\n",
      "train loss: 0.056:  75%|███████▌  | 150/200 [42:54<14:32, 17.45s/it]\u001b[A\n",
      "train loss: 0.050:  75%|███████▌  | 150/200 [43:12<14:32, 17.45s/it]\u001b[A\n",
      "train loss: 0.050:  76%|███████▌  | 151/200 [43:12<14:13, 17.42s/it]\u001b[A\n",
      "train loss: 0.057:  76%|███████▌  | 151/200 [43:29<14:13, 17.42s/it]\u001b[A\n",
      "train loss: 0.057:  76%|███████▌  | 152/200 [43:29<13:57, 17.45s/it]\u001b[A\n",
      "train loss: 0.054:  76%|███████▌  | 152/200 [43:47<13:57, 17.45s/it]\u001b[A\n",
      "train loss: 0.054:  76%|███████▋  | 153/200 [43:47<13:38, 17.42s/it]\u001b[A\n",
      "train loss: 0.054:  76%|███████▋  | 153/200 [44:04<13:38, 17.42s/it]\u001b[A\n",
      "train loss: 0.054:  77%|███████▋  | 154/200 [44:04<13:19, 17.37s/it]\u001b[A\n",
      "train loss: 0.054:  77%|███████▋  | 154/200 [44:21<13:19, 17.37s/it]\u001b[A\n",
      "train loss: 0.054:  78%|███████▊  | 155/200 [44:21<13:01, 17.37s/it]\u001b[A\n",
      "train loss: 0.054:  78%|███████▊  | 155/200 [44:38<13:01, 17.37s/it]\u001b[A\n",
      "train loss: 0.054:  78%|███████▊  | 156/200 [44:38<12:43, 17.35s/it]\u001b[A\n",
      "train loss: 0.054:  78%|███████▊  | 156/200 [44:56<12:43, 17.35s/it]\u001b[A\n",
      "train loss: 0.054:  78%|███████▊  | 157/200 [44:56<12:23, 17.29s/it]\u001b[A\n",
      "train loss: 0.052:  78%|███████▊  | 157/200 [45:13<12:23, 17.29s/it]\u001b[A\n",
      "train loss: 0.052:  79%|███████▉  | 158/200 [45:13<12:04, 17.25s/it]\u001b[A\n",
      "train loss: 0.055:  79%|███████▉  | 158/200 [45:30<12:04, 17.25s/it]\u001b[A\n",
      "train loss: 0.055:  80%|███████▉  | 159/200 [45:30<11:45, 17.20s/it]\u001b[A\n",
      "train loss: 0.052:  80%|███████▉  | 159/200 [45:47<11:45, 17.20s/it]\u001b[A\n",
      "train loss: 0.052:  80%|████████  | 160/200 [45:47<11:28, 17.20s/it]\u001b[A\n",
      "train loss: 0.056:  80%|████████  | 160/200 [46:05<11:28, 17.20s/it]\u001b[A\n",
      "train loss: 0.056:  80%|████████  | 161/200 [46:05<11:15, 17.32s/it]\u001b[A\n",
      "train loss: 0.054:  80%|████████  | 161/200 [46:22<11:15, 17.32s/it]\u001b[A\n",
      "train loss: 0.054:  81%|████████  | 162/200 [46:22<10:57, 17.31s/it]\u001b[A\n",
      "train loss: 0.053:  81%|████████  | 162/200 [46:39<10:57, 17.31s/it]\u001b[A\n",
      "train loss: 0.053:  82%|████████▏ | 163/200 [46:39<10:38, 17.27s/it]\u001b[A\n",
      "train loss: 0.054:  82%|████████▏ | 163/200 [46:57<10:38, 17.27s/it]\u001b[A\n",
      "train loss: 0.054:  82%|████████▏ | 164/200 [46:57<10:29, 17.48s/it]\u001b[A\n",
      "train loss: 0.052:  82%|████████▏ | 164/200 [47:14<10:29, 17.48s/it]\u001b[A\n",
      "train loss: 0.052:  82%|████████▎ | 165/200 [47:14<10:10, 17.46s/it]\u001b[A\n",
      "train loss: 0.056:  82%|████████▎ | 165/200 [47:32<10:10, 17.46s/it]\u001b[A\n",
      "train loss: 0.056:  83%|████████▎ | 166/200 [47:32<09:53, 17.45s/it]\u001b[A\n",
      "train loss: 0.049:  83%|████████▎ | 166/200 [47:49<09:53, 17.45s/it]\u001b[A\n",
      "train loss: 0.049:  84%|████████▎ | 167/200 [47:49<09:35, 17.44s/it]\u001b[A\n",
      "train loss: 0.057:  84%|████████▎ | 167/200 [48:07<09:35, 17.44s/it]\u001b[A\n",
      "train loss: 0.057:  84%|████████▍ | 168/200 [48:07<09:17, 17.41s/it]\u001b[A\n",
      "train loss: 0.053:  84%|████████▍ | 168/200 [48:24<09:17, 17.41s/it]\u001b[A\n",
      "train loss: 0.053:  84%|████████▍ | 169/200 [48:24<08:58, 17.38s/it]\u001b[A\n",
      "train loss: 0.055:  84%|████████▍ | 169/200 [48:41<08:58, 17.38s/it]\u001b[A\n",
      "train loss: 0.055:  85%|████████▌ | 170/200 [48:41<08:41, 17.37s/it]\u001b[A\n",
      "train loss: 0.053:  85%|████████▌ | 170/200 [48:59<08:41, 17.37s/it]\u001b[A\n",
      "train loss: 0.053:  86%|████████▌ | 171/200 [48:59<08:23, 17.35s/it]\u001b[A\n",
      "train loss: 0.054:  86%|████████▌ | 171/200 [49:16<08:23, 17.35s/it]\u001b[A\n",
      "train loss: 0.054:  86%|████████▌ | 172/200 [49:16<08:05, 17.32s/it]\u001b[A\n",
      "train loss: 0.054:  86%|████████▌ | 172/200 [49:33<08:05, 17.32s/it]\u001b[A\n",
      "train loss: 0.054:  86%|████████▋ | 173/200 [49:33<07:47, 17.32s/it]\u001b[A\n",
      "train loss: 0.052:  86%|████████▋ | 173/200 [49:50<07:47, 17.32s/it]\u001b[A\n",
      "train loss: 0.052:  87%|████████▋ | 174/200 [49:50<07:29, 17.30s/it]\u001b[A\n",
      "train loss: 0.055:  87%|████████▋ | 174/200 [50:08<07:29, 17.30s/it]\u001b[A\n",
      "train loss: 0.055:  88%|████████▊ | 175/200 [50:08<07:10, 17.24s/it]\u001b[A\n",
      "train loss: 0.051:  88%|████████▊ | 175/200 [50:25<07:10, 17.24s/it]\u001b[A\n",
      "train loss: 0.051:  88%|████████▊ | 176/200 [50:25<06:53, 17.22s/it]\u001b[A\n",
      "train loss: 0.056:  88%|████████▊ | 176/200 [50:42<06:53, 17.22s/it]\u001b[A\n",
      "train loss: 0.056:  88%|████████▊ | 177/200 [50:42<06:34, 17.16s/it]\u001b[A\n",
      "train loss: 0.054:  88%|████████▊ | 177/200 [50:59<06:34, 17.16s/it]\u001b[A\n",
      "train loss: 0.054:  89%|████████▉ | 178/200 [50:59<06:19, 17.26s/it]\u001b[A\n",
      "train loss: 0.052:  89%|████████▉ | 178/200 [51:17<06:19, 17.26s/it]\u001b[A\n",
      "train loss: 0.052:  90%|████████▉ | 179/200 [51:17<06:02, 17.28s/it]\u001b[A\n",
      "train loss: 0.054:  90%|████████▉ | 179/200 [51:34<06:02, 17.28s/it]\u001b[A\n",
      "train loss: 0.054:  90%|█████████ | 180/200 [51:34<05:44, 17.24s/it]\u001b[A\n",
      "train loss: 0.053:  90%|█████████ | 180/200 [51:51<05:44, 17.24s/it]\u001b[A\n",
      "train loss: 0.053:  90%|█████████ | 181/200 [51:51<05:26, 17.19s/it]\u001b[A\n",
      "train loss: 0.055:  90%|█████████ | 181/200 [52:08<05:26, 17.19s/it]\u001b[A\n",
      "train loss: 0.055:  91%|█████████ | 182/200 [52:08<05:12, 17.33s/it]\u001b[A\n",
      "train loss: 0.049:  91%|█████████ | 182/200 [52:26<05:12, 17.33s/it]\u001b[A\n",
      "train loss: 0.049:  92%|█████████▏| 183/200 [52:26<04:54, 17.30s/it]\u001b[A\n",
      "train loss: 0.057:  92%|█████████▏| 183/200 [52:43<04:54, 17.30s/it]\u001b[A\n",
      "train loss: 0.057:  92%|█████████▏| 184/200 [52:43<04:36, 17.26s/it]\u001b[A\n",
      "train loss: 0.053:  92%|█████████▏| 184/200 [53:00<04:36, 17.26s/it]\u001b[A\n",
      "train loss: 0.053:  92%|█████████▎| 185/200 [53:00<04:18, 17.22s/it]\u001b[A\n",
      "train loss: 0.055:  92%|█████████▎| 185/200 [53:17<04:18, 17.22s/it]\u001b[A\n",
      "train loss: 0.055:  93%|█████████▎| 186/200 [53:17<04:01, 17.23s/it]\u001b[A\n",
      "train loss: 0.053:  93%|█████████▎| 186/200 [53:34<04:01, 17.23s/it]\u001b[A\n",
      "train loss: 0.053:  94%|█████████▎| 187/200 [53:34<03:43, 17.19s/it]\u001b[A\n",
      "train loss: 0.054:  94%|█████████▎| 187/200 [53:51<03:43, 17.19s/it]\u001b[A\n",
      "train loss: 0.054:  94%|█████████▍| 188/200 [53:51<03:25, 17.12s/it]\u001b[A\n",
      "train loss: 0.054:  94%|█████████▍| 188/200 [54:08<03:25, 17.12s/it]\u001b[A\n",
      "train loss: 0.054:  94%|█████████▍| 189/200 [54:08<03:07, 17.04s/it]\u001b[A\n",
      "train loss: 0.052:  94%|█████████▍| 189/200 [54:25<03:07, 17.04s/it]\u001b[A\n",
      "train loss: 0.052:  95%|█████████▌| 190/200 [54:25<02:50, 17.06s/it]\u001b[A\n",
      "train loss: 0.055:  95%|█████████▌| 190/200 [54:42<02:50, 17.06s/it]\u001b[A\n",
      "train loss: 0.055:  96%|█████████▌| 191/200 [54:42<02:33, 17.05s/it]\u001b[A\n",
      "train loss: 0.051:  96%|█████████▌| 191/200 [54:59<02:33, 17.05s/it]\u001b[A\n",
      "train loss: 0.051:  96%|█████████▌| 192/200 [54:59<02:16, 17.02s/it]\u001b[A\n",
      "train loss: 0.056:  96%|█████████▌| 192/200 [55:16<02:16, 17.02s/it]\u001b[A\n",
      "train loss: 0.056:  96%|█████████▋| 193/200 [55:16<01:59, 17.04s/it]\u001b[A\n",
      "train loss: 0.054:  96%|█████████▋| 193/200 [55:33<01:59, 17.04s/it]\u001b[A\n",
      "train loss: 0.054:  97%|█████████▋| 194/200 [55:33<01:42, 17.01s/it]\u001b[A\n",
      "train loss: 0.053:  97%|█████████▋| 194/200 [55:50<01:42, 17.01s/it]\u001b[A\n",
      "train loss: 0.053:  98%|█████████▊| 195/200 [55:50<01:24, 16.98s/it]\u001b[A\n",
      "train loss: 0.054:  98%|█████████▊| 195/200 [56:08<01:24, 16.98s/it]\u001b[A\n",
      "train loss: 0.054:  98%|█████████▊| 196/200 [56:08<01:08, 17.10s/it]\u001b[A\n",
      "train loss: 0.054:  98%|█████████▊| 196/200 [56:25<01:08, 17.10s/it]\u001b[A\n",
      "train loss: 0.054:  98%|█████████▊| 197/200 [56:25<00:51, 17.08s/it]\u001b[A\n",
      "train loss: 0.054:  98%|█████████▊| 197/200 [56:42<00:51, 17.08s/it]\u001b[A\n",
      "train loss: 0.054:  99%|█████████▉| 198/200 [56:42<00:34, 17.07s/it]\u001b[A\n",
      "train loss: 0.050:  99%|█████████▉| 198/200 [56:59<00:34, 17.07s/it]\u001b[A\n",
      "train loss: 0.050: 100%|█████████▉| 199/200 [56:59<00:17, 17.07s/it]\u001b[A\n",
      "train loss: 0.056: 100%|█████████▉| 199/200 [57:16<00:17, 17.07s/it]\u001b[A\n",
      "train loss: 0.056: 100%|██████████| 200/200 [57:16<00:00, 17.16s/it]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "# with tf.Session() as sess:\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "print(\"Start training\")\n",
    "\n",
    "# initial_step = stat.get_t() if stat else 0\n",
    "# iterator = range(p.max_epoch, ncols=70, initial=initial_step)\n",
    "iterator = tqdm(range(p.max_epoch))\n",
    "\n",
    "i=0\n",
    "for epoch in iterator:\n",
    "    # print('Start epoch')\n",
    "    # 1. train\n",
    "    total_train_costs = []\n",
    "    for idx in range(p.max_epoch):\n",
    "        if (i+1)*p.batch_size > len(x_train):\n",
    "            i=0\n",
    "        x = X_train[i*p.batch_size:(i+1)*p.batch_size].reshape([p.batch_size, height, width, channel])\n",
    "        y = Y_train[i*p.batch_size:(i+1)*p.batch_size].reshape([p.batch_size, height, width, channel])\n",
    "        i += 1\n",
    "        _, cost = sess.run([optim, loss], feed_dict={inputs: x, truth: y})\n",
    "        total_train_costs.append(cost)\n",
    "        \n",
    "#     print('Start testing')\n",
    "    # 2. test\n",
    "#     total_test_costs = []\n",
    "#     for idx in range(p.test_step):\n",
    "#         if (i+1)*p.batch_size > len(x_train):\n",
    "#             i=0\n",
    "#         x = X_test[i*p.batch_size:(i+1)*p.batch_size].reshape([p.batch_size, height, width, channel])\n",
    "#         y = Y_test[i*p.batch_size:(i+1)*p.batch_size].reshape([p.batch_size, height, width, channel])\n",
    "#         i += 1\n",
    "#         cost = sess.run(loss, feed_dict={inputs: x, truth: y})\n",
    "#         total_test_costs.append(cost)\n",
    "\n",
    "#     avg_train_cost, avg_test_cost = np.mean(total_train_costs), np.mean(total_test_costs)\n",
    "    avg_train_cost = np.mean(total_train_costs)\n",
    "    # print('Start generation')\n",
    "    # 3. generate samples\n",
    "#     samples = generate_occlusions(sess, height, width, inputs, output)\n",
    "#     iterator.set_description(\"train loss: %.3f, test loss: %.3f\" % (avg_train_cost, avg_test_cost))\n",
    "    iterator.set_description(\"train loss: %.3f\" % avg_train_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_W8G3E7LzhJ2"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "a = sess.run(output, {inputs:X_test.reshape((len(X_test),1,time_steps,1))})\n",
    "result = a.flatten()\n",
    "librosa.output.write_wav('result.wav',result,sr)\n",
    "# ipd.Audio('result.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJnlSXeRc-cq"
   },
   "source": [
    "Once we are done, we close our Tensorflow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSqoP9c2c-cq"
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pixelrnn.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
